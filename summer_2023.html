<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title></title>
    <link rel="stylesheet" href="fall.css" media="all">
</head>
<body>
    <div class="lab-entry">
        <h3 class="date">June 20</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
        First group meeting of the summer with Eric, Thea, Jake, and Ethan.
        Discussed the initial documents that I need to review in order to 
        get started this summer. Afterwards, I worked with Thea. First, I forked
        the visualizing clonal trees comps project repository that was stored in 
        Jimmy Zhong's github. I then worked with Thea to figure out why the CASet/DISC
        paper disagreed in the evaluation of the real data trees with the evaluations 
        made by the visualization code. In doing the comparisons again using Layla's implementation
        of CASet and DISC, we found that it was <strong>in fact the paper that had it wrong</strong>. 
        <br>
        <br>
        Afterwards, Thea and I met with Eric and Layla. They came up with tasks for us to do such as
        creating a 1-sentence and 1-paragraph description of 'What is this Project ?' and 'What do we hope
        to accomplish ?'. In our spare time Layla also wants us to come up with more real data. They also
        noted that we should prioritize implementation things and evaluation.
        <br>
        <br>
        I then read through <a href="https://journals.biologists.com/jcs/article/121/11/1771/30038/The-importance-of-stupidity-in-scientific-research">The Importance of Stupidity in Research</a>. I also got halfway through a first read of <i>A Nested Model for Visualization Design and Validation</i>.
            <br>
            <br>
	    <strong>Hours logged:</strong> 9:30am - 3:30pm, 10:30pm - 12:30pm
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 21</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
        What is this project and what do we hope to accomplish?
        <br>
        <br>
        <u>1-sentence summary:</u>
        <br>
        <br>
          A web-based visualization tool that can be used to better understand evaluations made by tumor tree distance measures.
        <br>
        <br>
        <u>1-paragraph summary:</u>
        <br>
        <br>
          An accessible, easy-to-use web-based visualization tool that cancer researchers can use to better understand the 
          differences between two tumor phylogenies as evaluated by various ISA distance measures--CASet, DISC, 
          ancestor-descendant, parent-child. Better understanding the granularity behind the single number offered by 
          these distance measures could be useful in establishing trust in these evaluations. This can help in the adoption
          of these more robust methods of comparing tumor phylogenies by cancer biologists who may have limited command-line
          proficiency. Tasks that may be important to these users might be <u>exploring</u> the areas between trees that cause
          the largest difference between them. In order to appropriately support this task, we need to make instantly interpretable visualizations
          depicting how each mutations contributes to the distance between two tumor phylogenies. It will also be useful for users to <u>query</u>
          a specific mutation to see how it is contributing, and whether it is present in both trees or not. This tool could also be useful to researchers 
          in the area of tumor distance measures.
          A task that might be important to this audience is <u>discovering</u> how features of tree topologies might affect the
          evaluation of a distance measure--depth, branching factor, etc. A useful feature in service of this task could be summary
          statistics that denote the maximum depth and maximum branching factor of each tumor phylogeny. 
            <br>
            <br>
	    <strong>Hours logged: </strong> 9:45am - 6pm
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 22</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
        Started off by completing the 1-sentence and 1-paragraph summaries, the entirety of 
        which you can see recorded on the previous day. Then went to coffee hour and grabbed
        a free tea from Schulze and had pleasant conversations with many people including
        Jesse Lewis, whom I hope to contact more during my time as an Educational Associate for
        the CS department. I also met Dina, who is the new VP of inclusion at Carleton. After the 
        coffee hour, I went to have a meeting with Thea and Eric to discuss our 1-sentence and 1-paragraph
        summaries. Lots of good ideas were flying around, and some important considerations that came out
        of the meeting include but are not limited to...
        <ul>
        	<li>Who is the audience? Experimental cancer biologists? Computational biologists?</li>
        	<li>What are the tasks that users might desire?</li>
        	<li>We can get unbiased evaluations of tree comparisons from experts and compare them to our visualization</li>
        	<li>Models of evolution: linear, neutral, branched, punctuated</li>
        	<li>It will be helpful to write user stories</li>
        </ul>
        I then went to the library with Thea to get a copy of 'The Book of Trees' and to print out a paper about
        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cih-S4kAAAAJ&sortby=pubdate&citation_for_view=cih-S4kAAAAJ:2KloaMYe4IUC">tree task abstractions written by John A. Guerra-Gomez</a>. After our ice cream break, I've been focusing on
        that paper since. There was also an ice cream break.
            <br>
            <br>
	    <strong>Hours logged: </strong> 9:00pm - 5pm, 8pm - 8:30pm
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 23</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
        Continued to read 'A state-of-the-art survey of tasks for tree design and evaluation with a curated task dataset', learning more about tree task abstractions
        and thinking about how they can be useful to the work that we're doing. In general, by definining task abstractions for our clonal tree comparison visualization
        project, we can more easily find encodings that best support the tasks that we want. This can then be used to validate our visualization in regards to our encodings
        choices, something discussed in this <a href="https://ieeexplore.ieee.org/document/5290695">paper</a>. I also explored the <a href="https://osf.io/u5ehs/">dataset</a> that they curated. Found
        a <a href="https://ieeexplore.ieee.org/abstract/document/6065011">cool paper</a> comparing traditional, orthogonal, and radial node-link diagrams, resulting in a definite conclusion that radial node-link diagrams were the most difficult
        to draw conclusions from. 
    
        <br>
        <br>
        
        As a method of procrastination, I am looking at researchers whom we can ask to evaluate our visual tool:
        <ul>
        	<li>Anna Ritz (Reed College), computational biologist</li>
        	<li>Mohammed El-Kebir (UIUC), computational biologist</li>
        	<li>Jeremy Flanagan (Kansas City Cancer Center), oncologist, carleton alumn</li>
        	<li>Kevin Kensler (Weill Cornell), epidemiologist who does cancer research, carleton alumn</li>
        	<li>Craig Eckfeldt (University of Minnesota), epidemiologist who does cancer research</li>
        	<li>Azra Raza (Columbia University), oncologist, wrote book about the prevention of cancer but also mentions how cancer is incurable because we don't understand its evolutionary process</li> 
        </ul>
        <br>
        <br>
        I read Ch 12. of Munzner's 'Visualization Analysis and Design' which talked about integrating multiple views into your data visualization. It describes models such as
        multiform (same data, different encoding), overview-detail, detail-on-demand, linked highlighting, and more. I also continued to read the paper on tree task 
        abstractions.
            <br>
            <br>
	    <strong>Hours logged: </strong> 10:00am - 3:30pm, 11:30pm - 12:30am
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 24</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            I worked on filling out some documents for this Educational Associate position,
            I then worked on completing the Responsible Conduct for Research training. It seems
            that most of everything was done as a result of my doing research last year. I then
            translated some real data trees from the paper that introduced B-SCITE.
            <br>
            <br>
            As a method of procrastination, I then looked for the SCITE paper so that I could use
            it to generate tumor evolutionary histories. I think that understanding this will be 
            fulfilling for me and help motivate some of the stuff that we're doing in data vis.
            <br>
            <br>
	    <strong>Hours logged: </strong> 11:00am - 12:30pm 
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">Week 1 Status Report</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
        Questions:
        <ol>
        	<li>What did I hope to accomplish?</li>
        	<li>What did I actually accomplish</li>
        	<li>Why are (1) and (3) different?</li>
        	<li>What is my plan for next week??</li>
        	<li>What did I read this week?</li>
        	<li>Questions?</li>
        </ol>
        Answers:
        <ol>
        	<li>I was hoping to read a lot of literature regarding the evaluation of visualization tools. This meant reading literature specifically on evaluation but also the evaluation
 sections of papers that presented visualization tools. I was also hoping to get a better sense of the goals for this summer.</li>
        	<li>I ended up reading one paper talking specifically about evaluation--titled A Nested Model for Visualization Design and Validation. I also read a paper on task abstractions specifically as it pertains to tree visualizations--the paper was titled A State-of-the-Art Survey of Tasks for Tree Design and Evaluation with a Curated Task Dataset. I also read some of the paper on ClonArch, but lost interest as I realized that it wouldn't be very helpful; it tackles a different problem from tumor evolution, concerning itself more with the spatial clonal architecture of a tumor. The paper also lacked anything about evaluating the visualization tool, but from assessing other visualization tools in the computational biology community, this seems to be the norm. Evaluation of a visualization tool seems more of a focus in the data visualization community. Aside from papers, I worked a bit with Thea on verifying the correctness of the visualization tool we developed, wrote a 1-sentence/1-paragraph description of my interpretation for the goals of this project, translated some real data trees from a paper, and looked for some names of researchers whom we can reach out to during the evaluation stage of our tool.</li>
        	<li>The expectations and reality of this week differ primarily because of my lack of specificity for goals this week. I ended up doing a lot outside the scope of evaluation and thinking about how this summer should pan out. A lot of this stuff will have to overflow into the upcoming week just because of the schedule of our meetings as well--we at least plan on talking about plans for this summer more this upcoming week.</li>
        	<li>
                <ul>
                	<li>Translate more real data trees from papers.</li>
                	<li>Better organize the files in the github repo.</li>
                	<li>Better understand the goals for this summer.</li>
                	<li>Better understand the audience and tasks required of this visualization tool</li>
			<li>Design an experiment to evaluation our visualization tool</li>
                        <li>Define the task abstractions for our visualization tool and find papers that reinforce the validity of each visual encoding</li>
                        <li>Start filling in the GitHub Issues list</li>
                </ul>
                </li>
        	<li>
                <ul>
                	<li><a href="https://ieeexplore.ieee.org/abstract/document/5290695">A Nested Model for Visualization Design and Validation</a></li>
                	<li><a href="https://ieeexplore.ieee.org/abstract/document/9371413">A State-of-the-Art Survey of Tasks for Tree Design and Evaluation With a Curated Task Dataset</a></li>
                	<li><a href="https://academic.oup.com/bioinformatics/article/36/Supplement_1/i161/5870476">ClonArch: visualizing the spatial clonal architecture of tumors</a></li>
                	<li><a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0936-x">Tree inference for single-cell data</a></li>
                	<li><a href="https://journals.biologists.com/jcs/article/121/11/1771/30038/The-importance-of-stupidity-in-scientific-research">The importance of stupidity in scientific research</a></li>
                	<li>Ch. 12 of Munzner's 'Visualization Analysis and Design'</li>
                </ul>
                </li>
        	<li>Who is our audience for this tool and what tasks are most important for them for this tool?</li>
        </ol>
            <br>
            <br>
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 26</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            Started the day by attending new employee orientation, which lasted from 
            9am to 11am. I then spent some time getting Treeversity to work, which I
            finally accomplished. Rather than a website, it was an Java application that
            I had to run. I checked off some tasks from the overview document. I then met
            with Eric and Thea to talk about our synthesis of each person's 1-page writeup 
            for the project. I then spent the rest of the evening by working on and analyzing
            the heatmap. We also spent more time pulling in real data into the Observable.  
            <br>
            <br>
	    <strong>Hours logged: </strong> 9:00am - 6:00pm 
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 27</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            Had a brief, informal catchup with Thea, primarily concerned about the audience of this visualization
            tool and the logistics of reaching out to people. I then worked with Thea to flesh out the the user 
            stories. Then we had a formal group meeting with Eric, Thea, Layla, and me regarding the user stories
            and heatmap. We had a good discussion about these topics, especially the user stories. A big breakthrough
            was the importance of comparing trees to a ground truth. Eric then suggested that we consider the intersection
            version of the heatmap. Thea and I then worked on the heatmap on Observable some more. One pattern that we
            began noticing is that triangles in the heatmap are suggestive of a cluster being pulled out. Also, the ordering
            of mutations matters a lot in the heatmap.
            <br>
            <br>
	    <strong>Hours logged: </strong> 10:30am - 5:00pm 
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 28</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            Attended the Computational Suite weekly wednesday meet, talked to
            other research students. I then worked with Thea to clean up the Observable
            a bit. Afterwards, we then watched a video of John Alexis Guerra-Gomez in 
            which he discussed visualizing network data when there is a lot of nodes and edges.
            He seems like quite a character. Thea and I then brainstormed experiments that 
            we conduct with various audiences of our tool in order to evaluate the efficacy
            of our tool:
            <ul>
            	<li>
                  For the tumor distance researchers, give them two trees and a distance measure and ask them
                  to point out differences between the tree and what aspects might be contributing to the distance.
                  Then ask them to conduct the same task but with the assistance of the visualization tool.
                </li>
                <li>
                  For the tumor inference methods researchers, give them a variety of trees generated from a single method
                  and compare them to the ground truth tree. Ask them to explore and make discoveries.
                </li>
                <li>
                  For the cancer biologists who are more concerned with data than methods, 
                  ask the to rank the distance measures without the visualization tool. Then 
                  ask them to conduct the same task but with the help of the visualization tool.
                </li>
            </ul>

            <br>
            <br>
            Aside from that, we also worked to create a way to more easily parse newick strings in the Observable.
            After a few failed attempts, I ended up finding some observable code that performed a parsing of the newick strings.
            <br>
            <br>
	    <strong>Hours logged: </strong> 10:30am - 4:00pm, 6:00pm - 8:00pm 
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 29</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            I used the following command to help convert clusters with { to space delimited clusters.
            <br>
            <br>
            sed '/{*}/ s/,//g' &lt;filename&gt;
            <br>
            <br>
            Eric wants us to refactor api.py into app.py, so we'll try to get that done this week.
            I collaborated with Thea to make the <a href="https://observablehq.com/d/5a5928a7eb1e57bd">Observable</a>
            better by adding in more real data, writing code for parsing the newick strings and getting the appropriate 
            data from them (mutations, ad pairs, pc pairs), and tuning the radio buttons to easily change which trees we
            are comparing. We then presented this stuff at the lab meeting to Eric, Jake, and Ethan. We then attended the tea
            talk that Anna Rafferty gave about using applied machine learning in educational assessments. Following the talk,
            we continued to make the observable better by applying modularity to the tripartite graphs as well. We then spent
            time making inferences and comparing the heatmap and tripartite approaches. I then read a paper on design studies
            written by Tamara Munzner. 
            <br>
            <br>
	    <strong>Hours logged: </strong> 9:30am - 6:00pm, 10:00pm - 11:00pm
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">June 30</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            Reviewed and iterated upon the user stories and requirements. Refactored api.py and app.py into
            a combined file called combined_app_api.py. Contacted Eric about testing it, but doesn't seem to
            work, so we'll have to continue debugging that.  

            Worked with Thea on designing a version of the heatmap/tripartite graph for CASet and DISC. 
            Turns out, it is harder than we think, so after a couple hours of brainstorming, we couldn't
            come up with anything brilliant. We went home to let the ideas ruminate. That being that, Thea
            did mention turning CASet into something more similar to ancestor-descendant in that we should 
            somehow consider pairs of nodes as edges rather than totally using the idea of sets that CASet uses. 

            I then worked on creating a Newick parser to more better accommodate the data that we might receive
            from users. It turned out to be easier than I thought.
            <br>
            <br>
	    <strong>Hours logged: </strong> 11:00am - 3:30pm, 5pm - 7:30pm, 10:00pm - 12:30am
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">July 1</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            I completed and debugged the Newick parser. The code is linked <a href="">here</a>.
            I then used the output of this to visualize the individual mutation contributions, visualizations
            which are stored in our observable notebook, linked <a href="https://github.com/quocodile/visualize-clonal-trees/tree/main/newick_parser">here</a>. I had to write additional code
            to connect the two, and that took a bit longer than I would have liked, but was able to complete it. I 
            will check for correctness and analyze it with Thea on Monday.
            <br>
            <br>
	    <strong>Hours logged: </strong> 12:30pm - 2:30pm 
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">Week 2 Status Report</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
        Questions:
        <ol>
        	<li>What did I hope to accomplish?</li>
        	<li>What did I actually accomplish</li>
        	<li>Why are (1) and (3) different?</li>
        	<li>What is my plan for next week??</li>
        	<li>What did I read this week?</li>
        	<li>Questions?</li>
        </ol>
        Answers:
        <ol>
        	<li>
			<ul>
				<li>Translate more real data trees from papers.</li>
				<li>Better organize the files in the github repo.</li>
				<li>Better understand the goals for this summer.</li>
				<li>Better understand the audience and tasks required of this visualization tool</li>
				<li>Design an experiment to evaluate our visualization tool</li>
				<li>Define the task abstractions for our visualization tool and find papers that reinforce the validity of each visual encoding</li>
				<li>Start filling in the GitHub Issues list</li>
			</ul>
                </li>
                <br>
        	<li>
			<ul>
				<li>Enhanced the Observable by automating many tasks.</li>
				<li>Analyzed the heatmap and tripartite visualization for conveying individual mutation contributions</li>
				<li>Created and interated upon user stories and requirements</li>
				<li>Brainstormed experiments to evaluate the tool for a variety of audiences.</li>
				<li>Better organized the files in the github repo, focusing mainly on the organization of our real data.</li>
			</ul>
                </li>
                <br>
        	<li>What I accomlished versus what I hoped to accomplish differ because I decided that some things took precedent over (and were more exciting to work on than) others. Specifically, the goal of deciding on how to classify the abstract tasks required of our tool wasn't immediately necessary. Rather, what needed to be focused on what preparing for meeting with Mohammed, Layla's collaborator. As such, we needed to make sure that we had things to review. In addition to polishing out our tool, we also wanted our heatmap and tripartite visualizations, as well as the user stories to be reviewed. As such, we focused primarily on that stuff.</li>
                <br>
        	<li>The plan for this upcoming week is to get feedback from Mohammed regarding many aspects of our project--the user stories and requirements, the visualization tool, and the heatmap and tripartite graphs. We then want to iterate upon this feedback.</li>
                <br>
        	<li>N/A</li>
        </ol>
            <br>
            <br>
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">July 3</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            Got email regarding rebuttals for ACM BCB conference paper, so met with Layla to discuss that.
            Some tasks assigned to me are to put the experiment code into the repo, create document for reviews and responses.
            I then met with Thea to discuss the CASet heatmap that I had worked on based off of an idea provided by her. We 
            then tried gaining insights from it, but as expected, the heatmap has a high learning curve. Aside from this, we
            met with Layla and Eric to discuss a few things--the heatmap, tripartite graph, and overall schedule with Mohammmed.
            I then worked on implementing clusters for the tripartite graph. I also printed out an article abouth insight-driven
            evaluation of visualization tools, one of the articles written by Chris North. In our meeting, Layla also mentioned a 
            computational biologist named Jaime Divila from St. Olaf as someone we could reach out to.
            <br>
            <br>
	    <strong>Hours logged: </strong> 10:30am - 4:30pm, 6:00pm - 8pm 
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">July 4</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            Worked with Thea to organize a schedule and documents for when Mohammed arrives.
            <br>
            <br>
	    <strong>Hours logged: </strong> 3:30pm - 5pm 
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">July 5</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            <br>
            <br>
	    <strong>Hours logged: </strong> 10:30am...  
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">July 6</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            Met with Layla to go over the first rebuttal for paper submitted to ACM 
            BCB 2023. Read and edited a script Thea created for the open-ended user study
            that we would do with Mohammed. From the actual informal study itself, we gained
            a lot of high level insights of what the tool could become and also general insights
            about the usability of our interface. Whlie Thea recorded a video, I have some notes
            linked here <a href="https://drive.google.com/file/d/19-xDEkGM44vQRtF4Ui04wvC2X3y8WeGV/view?usp=drive_link">here</a> 
            <br>
            <br>
	    <strong>Hours logged: </strong> 11:00am - 4:30pm 
        </p>
    </div>
    <div class="lab-entry">
        <h3 class="date">July 7</h3>
        <p ondrop="drop(event)" ondragover="allowDrop(event)" class="content">
            Met with Layla to go over and submit the final rebuttal for paper submitted to ACM
            BCB 2023. Began reading a paper that described Mesquite, a phylogenetics comparison
            software. Uploaded evaluation code and experimental data to bitbucket to ensure reproducibility as
            suggested by the reviewer. Met with everyone, including Mohammed, to brainstorm the directions for 
            VECTr. One big takeaway is that it will be hard to balance the needs and wants across
            multiple different audiences. It seems the best approach, at least initially, to focus
            on a single group out of the categories listed under methods-driven computational biologists.
            We then added tasks to complete into our <a href="https://github.com/quocodile/visualize-clonal-trees/issues">Github Issues</a>.
            <br>
            <br>
	    <strong>Hours logged: </strong> 10:30am - 4:00pm  
        </p>
    </div>
    <script src="fall.js"></script>
</body>
</html>
